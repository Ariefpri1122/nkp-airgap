MULTI KUBERNETES CLUSTER ENVIRONMENTS
-------------------------------------

*** Create 2nd Managed Kubernetes Cluster ***

Secondary vlan IP range     :   x.x.x.132-254   --> By default secondary IP is still FREE
Secondary IPAM              :   x.x.x.161-253



Using NKP Dashboard - Your Name Workspace - Select Clusters from left pane menu
    -   Click Add Cluster - Create Cluster
        -   Cluster Name            			:   	yourname-nkp-drc (Ex: arief-nkp-drc)
        ⁃	SSH Public Key				:	ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEWT+eSeTQYYX7mIhQGghmSm418n9ANHLX9nZ//eGISr arief.pribadi@nutanix.com
		⁃	Nutanix Prism Project		:	lab
		⁃	Nutanix AOS Cluster		:	PHX-POC334
		⁃	Subnet				:	aux-1 --> Your secondary Subnet
		⁃	OS Image			:	nkp-rocky-9.5-release-1.31.9-20250702204537.qcow2
		⁃	CP End Point IP			:	1st IP from secondary vlan (132) --> make sure checked by PING or IP Scanner its a FREE IP (ex: 10.38.106.132)
		⁃	CP Node Count			:	1
		⁃	CPU Per Node (vCPU)		:	4
		⁃	Memory Per Node			:	12
		⁃	Disk Size Per Node		:	80
		⁃	Nutanix Prism Project		:	lab
        ⁃	Nutanix AOS Cluster			:	PHX-POC334
		⁃	Subnet				:	aux-1 --> Your secondary Subnet
		⁃	OS Image			:	nkp-rocky-9.5-release-1.31.9-20250702204537.qcow2
		⁃	Worker Node Count		:	4
		-	CPU Per Node (vCPU)		:	8
		⁃	Memory Per Node			:	12
		⁃	Disk Size Per Node		:	80
		⁃	Storage Container			default

        *** PAY ATTENTION TO BELOW CONFIGURATION ***

        -   Pod Network             :   192.168.1.0/16  (NOT --> 192.168.0.0/16)
        -   Service Network         :   10.96.1.0/12    (NOT --> 10.96.0.0/12)


		⁃	Load Balancing Start			:	x.x.x.140)--> (by default secondary vlan is free) (ex: 10.38.106.140)
		⁃	Load Balancing End			:	x.x.x.150 --> make sure checked by PING or IP Scanner its a FREE IP (ex: 10.38.106.150)
		⁃	Image Registry Mirror	
			⁃	URL				:	https://airgap.arief.com:5000
			⁃	username			:	admin
			⁃	password			:	nutanix/4u
			⁃	CA				:	downloaded cert.crt
		⁃	Private Registry	
			⁃	URL				:	https://10.38.13.140:5000	# Your harbor URL Access as noted above
			⁃	username			:	nutanix
			⁃	password			:	nx2Tech974!
			⁃	CA				:	downloaded ca.cert
	-	Create

Using NKP Dashboard - Your Name Workspace - Select Clusters from left pane menu
    -   Click yourname-nkp-drc cluster - Application
        *   Make sure all the application in starts "Deployed" not "Enable"

	- Generate Token (by clicking your username from the right top corner)
	- Login using above username and password
		* Put the CA Certificate into your .kube directory --> Copy and Paste in code-server terminal (bastion)
		* These commands will update ~/.kube/config --> Copy and Paste in code-server terminal (bastion) 4x times
		* from code-server terminal --> kubectl get nodes
	- Modify your .kube\config 'context name' with more friendly name
		* ex: name: objective_chaplygin-10.38.106.53 (Managed Cluster) --> for managed cluster
		* ex: name: objective_chaplygin-10.38.106.41 (Kommander) --> for commander cluster
        * ex: name: objective_chaplygin-10.38.106.32 (Managed DRC) --> for managed DRC cluster
	- use kubectx to switch between cluster-context


*** Use Valero to Backup 1st Managed Cluster ***

1.  Install Velero CLI
    - From Code-server (bastion mv)
        *   curl -L https://github.com/vmware-tanzu/velero/releases/download/v1.15.2/velero-v1.15.2-linux-amd64.tar.gz -o velero.tar.gz
        *   tar -xvf velero.tar.gz
        *   sudo mv velero-v1.15.2-linux-amd64/velero /usr/local/bin/
        *   velero version -n kommander

2.  From Prism Central (PC) - Unified Storage - Objects
    -   Take a note on Object Store ntnxlab Object public IP --> ex: 10.38.106.8
    -   Click ntnxlab Object Stores
    -   Click Buckets Tab - Create Bucket
        * Name      :   velero-backup
        * Create
    -   From bucket tab
        * click velero-backup - User Access - Edit User Access - Add Users and Permissions
        * Add Administrator with FULL ACCESS
        * Save
    -   Click Access Key
        * Choose Administrator - Manage
        * Add Key - Generate Key
        * Download Key

            Username: administrator
            Access Key: kzj-yB1gXXG1h0_57-15JGVQx4pd29Mo
            Secret Key: ytexinDnjN2kK1TGvNMWH4Al2ykmo6VV
            Display Name: Administrator
            Tag: buckets-access-key-XSwkYvRMQCVvpOGYkeVrZbdr

    *** Check Bucket Connectivity ***

        - Install AWS Cclient   
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install

        - Create Temporary Credential

mkdir ~/.aws

cat > ~/.aws/credentials <<EOF
[ntnx-object-nkp]
aws_access_key_id = kzj-yB1gXXG1h0_57-15JGVQx4pd29Mo                            #   YOUR_KEY_ID
aws_secret_access_key =  ytexinDnjN2kK1TGvNMWH4Al2ykmo6VV                       #   YOUR_SECRET_KEY
EOF

cat > ~/.aws/config <<EOF
[profile ntnx-object-nkp]
region = us-east-1
s3 =
endpoint_url = http://10.38.106.8:80
addressing_style = path
EOF

        - Check list bucket

AWS_PROFILE=ntnx-object-nkp aws s3 ls --endpoint-url http://10.38.106.8:80

output ex:  2025-08-03 12:54:22 velero-backup

AWS_PROFILE=ntnx-object-nkp aws s3 ls s3://velero-backup --endpoint-url http://10.38.106.8:80

output  ex: nothing --> no files yet

3.  From code-server (bastion vm)
    -   kubectx --> to your kommander
    -   kubectl get kommandercluster -A --> take note on your kommander namespace (ex: kommander)
    -   kubectl get cluster -A --> take no on your kommander cluster name (ex: airgapped-hm-nkp-demo-2)
    -   kubectl get crd | grep velero --> valero.io CRD (Custom Resource Definition) listed
    -   kubectl get pod -n kommander | grep velero  --> check velero installation

        object-bucket-claims-check-dkp-velero-t2zk4                       0/1     Completed   0                2d13h
        velero-5fc979457d-5hbh5                                           1/1     Running     0                2d13h
        velero-backup-storage-location-updater-b79cb4bdd-hb7q9            1/1     Running     0                2d13h
        velero-pre-install-r6cvk                                          0/1     Completed   0                2d13h

    -   kubectl logs -n kommander deploy/velero | grep 'Plugin kind:'   --> velero-plugin-for-aws (init)

4.  From code-server (bastion vm)
        export CLUSTER_NAME=airgapped-hm-nkp-demo-2                     # Your Kommander Cluster Name in No. 2 Above
        export BUCKET=velero-backup                                     # Your Bucket Name in No. 1 Above
        export WORKSPACE_NAMESPACE=kommander                            # Your kommander namespace Name in No. 2 Above
        export BSL_NAME=ntnx-object-nkp 
        export NUTANIX_OBJECTS_HOST=10.38.106.8                         # Your Object Store in No. 1 Above
        export NUTANIX_OBJECTS_PORT=80
        export NUTANIX_OBJECTS_SECRET=velero-nutanix-credentials
        export AWS_PROFILE=ntnx-object-nkp
        export NUTANIX_OBJECTS_ACCESS_KEY_ID=kzj-yB1gXXG1h0_57-15JGVQx4pd29Mo           # Your Object Store AccessKey in No. 1 Above
        export NUTANIX_OBJECTS_SECRET_ACCESS_KEY=ytexinDnjN2kK1TGvNMWH4Al2ykmo6VV       # Your Object Store SecretKey in No. 1 Above

5.  From code-server (bastion vm)

*** Create Secret to Store Bucket Credential***

kubectx --> choose kommander cluster

kubectl apply -f - <<EOF 
apiVersion: v1
kind: Secret
metadata:
  name: ${NUTANIX_OBJECTS_SECRET}
  namespace: ${WORKSPACE_NAMESPACE}  
type: Opaque
stringData:
  aws: |
    [${AWS_PROFILE}]
    aws_access_key_id=${NUTANIX_OBJECTS_ACCESS_KEY_ID}
    aws_secret_access_key=${NUTANIX_OBJECTS_SECRET_ACCESS_KEY}
EOF

kubectl get secret ${NUTANIX_OBJECTS_SECRET} -n ${WORKSPACE_NAMESPACE} -o jsonpath="{.data.aws}" | base64 --decode

Ex:

[ntnx-object-nkp]
aws_access_key_id=kzj-yB1gXXG1h0_57-15JGVQx4pd29Mo
aws_secret_access_key=ytexinDnjN2kK1TGvNMWH4Al2ykmo6VV

*** Create ConfigMap to Create backupStorageLocation (BSL) of Velero ***

kubectx --> choose kommander cluster


velero --kubeconfig ${CLUSTER_NAME}.conf backup-location create ${BSL_NAME} -n ${WORKSPACE_NAMESPACE} --provider aws --bucket ${BUCKET} --credential ${NUTANIX_OBJECTS_SECRET}=aws --config region=us-east-1,insecureSkipTLSVerify="true",s3ForcePathStyle="true",profile=${AWS_PROFILE},s3Url=http://${NUTANIX_OBJECTS_HOST}:${NUTANIX_OBJECTS_PORT}

kubectl get bsl -n ${WORKSPACE_NAMESPACE}

Output Ex:

NAME              PHASE       LAST VALIDATED   AGE   DEFAULT
ntnx-object-nkp   Available   34s              54m   

kubectl get backupstoragelocations -n ${WORKSPACE_NAMESPACE} -oyaml --> to troubleshoot if the status NOT "available".

7.  Backup Process

*** Test backup ***

    -   velero backup create nutanix-velero-testbackup -n ${WORKSPACE_NAMESPACE} --storage-location ntnx-object-nkp --snapshot-volumes=false
    -   velero backup describe nutanix-velero-testbackup
    -   AWS_PROFILE=ntnx-object-nkp aws s3 ls s3://velero-backup --endpoint-url http://10.38.106.8:80

Check Bucker from Prism Central:

  - From your Prism Central (PC) dasbboard - Unified Storage - Object - Object Stores (Ex: ntnxlab)
      - Click your Object Store (ex: ntnxlab) - Buckets
          * Click "Launch Objects Browser"
          * input your Access and Secret Keys and Login
          * Click your velero-backup
          * You will find new backup folder - click backup folder
          * You will see your backup job folder - click it
          * You will see all arficact backup
